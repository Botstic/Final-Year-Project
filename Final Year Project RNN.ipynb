{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08b4b2b-e551-4745-97da-a1855497e20e",
   "metadata": {},
   "source": [
    "Final Year Project Shan Balendra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c1890c-efa6-4b71-a93f-82cf1ffb5916",
   "metadata": {},
   "source": [
    "This is the second Recurrent Neural Network(CNN). \n",
    "The code is made to run locally on an NVIDIA GPU using CUDA.\n",
    "The dataset input can be changed by modifying the line: \"dataset = NetworkTrafficDataset(data_folder='C:\\\\Users\\\\ShanB\\\\Documents\\\\Final Year Project Files')\"\n",
    "To run this code please extract the entire zip folder and change the directory path below to the path for the folder.\n",
    "\n",
    "This code was run on a machine running CUDA 12.1, PyTorch 2.3.0, python 3.12. On windows 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307b299d-c4bf-4141-9191-d1fb2ff54175",
   "metadata": {},
   "source": [
    "Import the neccessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8133e049-5b68-4c0f-b6ce-ddf5e2aed059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e70f2-0705-4a2a-97b1-4638e6fd8306",
   "metadata": {},
   "source": [
    "Define the CNN Model and the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdaa2429-6ca6-4f45-98dd-491f46e75b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model definition\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399ce925-e113-4137-b26b-6642ff595127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = 'C:/Users/ShanB/Documents/Final Year Project Files/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv'\n",
    "data = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c9d0c5-8224-4e63-ad92-467279b5b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "data.columns = data.columns.str.strip()\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data['Label'])\n",
    "num_classes = len(np.unique(labels))  # Determine number of classes dynamically\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data.drop('Label', axis=1))\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4ca350-d439-4337-84c4-99cfd8eec63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)  # Add sequence dimension\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoaders\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "model = RNN(1, 128, 2, num_classes).to(device)  # Assuming each feature is a single time step\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ea886a-550b-4ef3-a344-bdf0649e7dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0925\n",
      "Epoch [2/5], Loss: 0.0119\n",
      "Epoch [3/5], Loss: 0.0123\n",
      "Epoch [4/5], Loss: 0.1154\n",
      "Epoch [5/5], Loss: 0.0247\n"
     ]
    }
   ],
   "source": [
    "# Function to train the model\n",
    "def train_model(num_epochs, model, loaders):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in loaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Training the model\n",
    "train_model(5, model, {'train': train_loader, 'test': test_loader})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d7d93a-9018-412e-babf-4fdbecfed4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on test data: 99.11298218131975%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(loader, model):\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on test data: {100 * correct / total}%')\n",
    "\n",
    "evaluate_model(test_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7154cc-4f2b-4a5e-b3d6-d5dac618b0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881da5da-d43b-48b7-8d00-c9427fe042a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
